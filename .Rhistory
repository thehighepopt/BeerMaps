batting_tbl %>% count(playerID, wt = G)
batting_tbl %>% count(playerID, wt = G, sort = TRUE)
}
spices <- data.frame(arrange(tally(gb$recipe),desc(freq)))
spices <- data.frame(arrange(tally(gb$material),desc(freq)))
View(gb)
brats$material <- as.character(brats$material)
spices <- data.frame(tally(gb$material,sort = TRUE))
gb <- group_by(brats,material)
spices <- data.frame(tally(gb$material,sort = TRUE))
gb <- tally(group_by(brats,material) )
View(gb)
spices <- data.frame(tally(group_by(brats,material),sort = TRUE )
)
rm(gb)
brats$material <- as.character(brats$material)
brats$amount <- as.numeric(brats$amount)
spices <- data.frame(tally(group_by(brats,material),sort = TRUE )
)
names(spices) <- c("material","count")
brats$grams <- ifelse(brats[,3] == "tsp", brats$grams <- brats$amount * 4.93,
ifelse(brats[,3] == "tbsp", brats$grams <- brats$amount * 15,
ifelse(brats[,3] == "lbs", brats$grams <- brats$amount * 453.6,
ifelse(brats[,3] == "g", brats$grams <- brats$amount * 1, NA))))
bymat <- brats %>% group_by(material) %>% summarise_each(funs(mean),grams)
spices <- join(spices,bymat,by="material")
View(spices)
View(bymat)
is.na(bymat) <- 0
is.na(bymat$grams) <- 0
View(bymat)
bymat[(is.na(bymat)] <- 0
bymat[is.na(bymat)] <- 0
View(bymat)
View(brats)
brats[is.na(brats)] <- 0
bymat <- brats %>% group_by(material) %>% summarise_each(funs(mean),grams)
spices <- join(spices,bymat,by="material")
View(spices)
brats <- read.csv('C:/Users/stephen.p.duffy/Documents/GitHub/New Folder/Brats.csv')
brats$material <- as.character(brats$material)
brats$amount <- as.numeric(brats$amount)
spices <- data.frame(tally(group_by(brats,material),sort = TRUE ))
names(spices) <- c("material","count")
brats$grams <- ifelse(brats[,3] == "tsp", brats$grams <- brats$amount * 4.93,
ifelse(brats[,3] == "tbsp", brats$grams <- brats$amount * 15,
ifelse(brats[,3] == "lbs", brats$grams <- brats$amount * 453.6,
ifelse(brats[,3] == "g", brats$grams <- brats$amount * 1, NA))))
brats[is.na(brats)] <- 0
bymat <- brats %>% group_by(material) %>% summarise_each(funs(mean),grams)
spices <- join(spices,bymat,by="material")
View(spices)
install.packages("caret")
library(kernlab)
library(caret)
brats <- read.csv('C:/Users/stephen.p.duffy/Documents/GitHub/New Folder/Brats.csv')
brats$material <- as.character(brats$material)
brats$amount <- as.numeric(brats$amount)
spices <- data.frame(tally(group_by(brats,material),sort = TRUE ))
names(spices) <- c("material","count")
brats$grams <- ifelse(brats[,3] == "tsp", brats$grams <- brats$amount * 4.93,
ifelse(brats[,3] == "tbsp", brats$grams <- brats$amount * 15,
ifelse(brats[,3] == "lbs", brats$grams <- brats$amount * 453.6,
ifelse(brats[,3] == "g", brats$grams <- brats$amount * 1, NA))))
brats[is.na(brats)] <- 0
bymat <- brats %>% group_by(material) %>% summarise_each(funs(mean),grams)
spices <- join(spices,bymat,by="material")
View(spices)
View(bymat)
library(kernlab)
data(spam)
data("faithful")
inTrain <- createDataPartition(y=faithful$waiting, p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,]
testFaith <- faithful[-inTrain,]
head(trainFaith)
install.packages("ILSR")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
View(predictors)
data("concrete")
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(concrete)
qplot(CompressiveStrength.,finMod$residuals, colour=race,data=training)
View(testing)
View(training)
qplot(CompressiveStrength ~ .,colour=.,data=concrete)
qplot(CompressiveStrength ~ .,colour=concrete[,1:8],data=concrete)
featurePlot(x=training[,1:8],
y=training$CompressiveStrength,
plot="pairs")
librar(Hmisc)
library(Hmisc)
featurePlot(x=concrete[,1:8],
y=concrete$CompressiveStrength,
plot="pairs")
conc2 <- concrete
summary(conc2$FlyAsh)
conc2$FlyAsh <- cut2(conc2$FlyAsh,c(25,50,75,100,125,150,175,200))
summary(conc2$Age)
conc2$FlyAsh <- cut2(conc2$FlyAsh,c(50,100,150,200,250,300))
conc2$Age <- cut2(conc2$Age,c(50,100,150,200,250,300))
featurePlot(x=conc2[,1:8],
y=conc2$CompressiveStrength,
plot="pairs")
View(conc2)
summary(conc2)
conc2$Water <- cut2(conc2$Water,c(50,100,150,200,250,300))
conc2$BlastFurnaceSlag <- cut2(conc2$BlastFurnaceSlag,c(50,100,150,200,250,300))
conc2$CourseAggregate <- cut2(conc2$CourseAggregate,c(100,200,300,400,500,600,700,800,900))
conc2$CoarseAggregate <- cut2(conc2$CoarseAggregate,c(100,200,300,400,500,600,700,800,900))
conc2$FineAggregate <- cut2(conc2$FineAggregate,c(100,200,300,400,500,600,700,800,900))
conc2$Superplasticizer <- cut2(conc2$Superplasticizer,c(5,10,15,20,25,30))
conc2$Cement <- cut2(conc2$Cement,c(100,200,300,400,500))
featurePlot(x=conc2[,1:8],
y=conc2$CompressiveStrength,
plot="pairs")
featurePlot(x=training[,1:8],
y=training$CompressiveStrength,
plot="pairs")
index <- seq_along(1:nrow(training))
ggplot(data=training, aes(x=index,y=CompressiveStrength)) + geom_point() + theme_bw()
ggplot(data = training, aes(x = index, y = CompressiveStrength)) + geom_point() +
theme_bw()
cutCS <- cut2(training$CompressiveStrength, g = 4)
summary(cutCS)
ggplot(data = training, aes(y = index, x = cutCS)) + geom_boxplot() + geom_jitter(col = "blue") +
theme_bw()
View(mixtures)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
ggplot(data = training, aes(x = index, y = CompressiveStrength)) + geom_point() +
theme_bw()
index <- seq_along(1:nrow(training))
ggplot(data = training, aes(x = index, y = CompressiveStrength)) + geom_point() +
theme_bw()
cutCS <- cut2(training$CompressiveStrength, g = 4)
summary(cutCS)
ggplot(data = training, aes(y = index, x = cutCS)) + geom_boxplot() + geom_jitter(col = "blue") +
theme_bw()
featurePlot(x = training[, names], y = cutCS, plot = "box")
featurePlot(x = training[, 1:8], y = cutCS, plot = "box")
hist(training$Superplasticizer)
View(mixtures)
summary(mixtures$Superplasticizer)
summary(cement$Superplasticizer)
summary(concrete$Superplasticizer)
hist(log(mixtures$Superplasticizer))
hist(log10(mixtures$Superplasticizer))
summary(log10(cement$Superplasticizer))
summary(log10(concrete$Superplasticizer))
g <- log10(concrete$Superplasticizer)
plot(g)
hist(g)
summary(g)
g <- log(concrete$Superplasticizer)
plot(g)
hist(g)
g <- log(mixtures$Superplasticizer)
plot(g)
hist(g)
summary(g)
g <- log(mixtures$Superplasticizer+1)
hist(g)
g <- log(training$Superplasticizer)
hist(g)
summary(g)
hist(training$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]];training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
match("IL",names(training))
lab <- glob2rx("IL*")
grep(lab,training)
lab <- glob2rx("IL_*")
grep(lab,training)
grep(lab,training,value = TRUE)
grep(lab,names(training))
grep(glob2rx("IL*"),names(training))
cols <- grep(glob2rx("IL*"),names(training))
b <- training[,cols]
View(b)
g <- preProcess(b,thresh = .80)
g
g[1]
g[2]
g[3]
g[4]
g[5]
g[6]
g[7]
g[8]
g[9]
g[10]
g[11]
g[12]
g[13]
g[14]
g <- preProcess(b,method = "pca", thresh = .80)
g[4]
traing <- predict(g,b)
View(traing)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]];training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]];training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
cols <- grep(glob2rx("IL*"),names(training))
b <- training[,c(1,cols)]
View(b)
pred1 <- glm(diagnosis ~ ., data = training)
View(training)
pred1 <- glm(diagnosis ~ ., data = b)
View(b)
b[,2:13] <- as.numeric(b[,2:13])
b[,2] <- as.numeric(b[,2])
b[,3:4] <- as.numeric(b[,3:4])
sapply(b, as.numeric(b))
b[,3] <- as.numeric(b[,3])
b[,4] <- as.numeric(b[,4])
b[,5] <- as.numeric(b[,5])
b[,6] <- as.numeric(b[,6])
b[,7] <- as.numeric(b[,7])
b[,8] <- as.numeric(b[,8])
b[,9] <- as.numeric(b[,9])
b[,10] <- as.numeric(b[,10])
b[,11] <- as.numeric(b[,11])
b[,12] <- as.numeric(b[,12])
b[,13] <- as.numeric(b[,13])
pred1 <- glm(diagnosis ~ ., data = b)
str(b)
b[,1] <- as.character(b[,1])
pred1 <- glm(diagnosis ~ ., data = b)
View(b)
pred1 <- lm(diagnosis ~ ., data = b)
cols <- grep(glob2rx("IL*"),names(training))
b <- training[,c(1,cols)]
b[,3] <- as.numeric(b[,3])
b[,4] <- as.numeric(b[,4])
b[,5] <- as.numeric(b[,5])
b[,6] <- as.numeric(b[,6])
b[,7] <- as.numeric(b[,7])
b[,8] <- as.numeric(b[,8])
b[,9] <- as.numeric(b[,9])
b[,10] <- as.numeric(b[,10])
b[,11] <- as.numeric(b[,11])
b[,12] <- as.numeric(b[,12])
b[,13] <- as.numeric(b[,13])
pred1 <- glm(diagnosis ~ ., data = b)
pred1 <- lm(diagnosis ~ ., data = b)
summary(pred1)
View(b)
str(b)
b[,1] <- as.factor(b[,1])
str(b)
pred1 <- lm(diagnosis ~ ., data = b)
pred1 <- train(diagnosis ~ .,method ="glm", data=b)
install.packages('e1071', dependencies=TRUE)
pred1 <- train(diagnosis ~ .,method ="glm", data=b)
summary(pred1)
C1 <- confusionMatrix(predictions, testing$diagnosis)
C1 <- confusionMatrix(b, pred1$diagnosis)
predictions <- predict(modelFit, newdata = testing)
predictions <- predict(pred1, newdata = b)
C1 <- confusionMatrix(predictions, pred1$diagnosis)
C1 <- confusionMatrix(predictions, b$diagnosis)
c1
C1
A1 <- C1$overall[1]
A1
pred2 <- train(diagnosis ~ .,method ="glm",preProcess = "pca", data=b)
predictions2 <- predict(pred2, newdata = b)
C2 <- confusionMatrix(predictions2, b$diagnosis)
A1 <- C2$overall[1]
A1 <- C1$overall[1]
A2 <- C2$overall[1]
A1;A2
pred2 <- train(diagnosis ~ .,method ="glm",preProcess = "pca", data=b, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
predictions2 <- predict(pred2, newdata = b)
C2 <- confusionMatrix(predictions2, b$diagnosis)
A2 <- C2$overall[1]
A1;A2
predictions2 <- predict(pred2, newdata = testing)
C2 <- confusionMatrix(predictions2, testing$diagnosis)
A2 <- C2$overall[1]
pred1 <- train(diagnosis ~ .,method ="glm", data=b)
C1 <- confusionMatrix(predictions, testing$diagnosis)
C1 <- confusionMatrix(pred1, testing$diagnosis)
predictions <- predict(pred1, newdata = testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
A1 <- C1$overall[1]
A1;A2
cols <- grep(glob2rx("IL*"),names(training))
b <- training[,cols]
g <- preProcess(b,method = "pca", thresh = .90)
traing <- predict(g,b)
traing
View(traing)
install_github('ramnathv/rCharts')
library(devtools)
install_github('ramnathv/rCharts')
library(rCharts)
hair_eye = as.data.frame(HairEyeColor)
rPlot(Freq ~ Hair | Eye, color = 'Eye', data = hair_eye, type = 'bar')
haireye <- as.data.frame(HairEyeColor)
n1 <- nPlot(Freq ~ Hair, group = 'Eye', type = 'multiBarChart', data = subset(haireye, Sex == 'Male'))
nPlot(Freq ~ Hair, group = 'Eye', type = 'multiBarChart', data = subset(haireye, Sex == 'Male'))
n1 <- nPlot(Freq ~ Hair, group = 'Eye', type = 'multiBarChart', data = subset(haireye, Sex == 'Male'))
install.packages('slidify')
n1 <- nPlot(Freq ~ Hair, group = 'Eye', type = 'multiBarChart', data = subset(haireye, Sex == 'Male'))
n1$save('fig/n1.html',cdn =TRUE)
cat('<iframe src="fig/n1/html" width=100%, height=600></iframe>')
names(iris) = gsub("\\.", "", names(iris))
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
install.packages('morris')
library(leaflet)
library(highchart)
install.packages('highchart')
install.packages('googleviz')
install_github("slidify/ramnathv")
install_github("slidify", "ramnathv")
install_github("ramnathv/slidify")
library(slidify)
install.packages('googleVis')
suppressPackageStartupMessages(library(googleVis))
M <- gvisMotionChart(Fruits,"Fruit","Year",options = list(width = 600, height = 400))
print(M,"chart")
plot(M)
G <- gvisGeoChart(Exports, locationvar = "Country", colorvar = "Profit", options = list(width = 600,
height = 400))
plot(G)
G <- gvisGeoChart(Exports, locationvar = "Country", colorvar = "Profit", options = list(width = 600,
height = 400, region = "150"))
plot(G)
demo(googleVis)
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
plot(myplot)
plot(myPlot)
myPlot(s)
myPlot(5)
myPlot(1.3)
myPlot(.3)
library(rsconnect)
library(shiny)
library(shinyapps)
library(devtools)
library(ggplot2)
library(rCharts)
dTable(airquality, sPaginationType = "full_numbers")
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text')
h3('Sidebar')
),
mainPanel(
h3('Main Panel text')
)
))
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text')
h2('Sidebar')
),
mainPanel(
h2('Main Panel text')
)
))
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text') ,
h3('Sidebar')),
mainPanel(
h3('Main Panel text')
)
))
shiny::runApp('GitHub/DataProducts')
library(rvest)
library(magrittr)
library(plyr)
library(stringr)
setwd("C:/Users/Stephen.P.Duffy/Documents/GitHub/BeerMaps")
##Capture HTML From BA Top 250 website and Parse it
top250web <- read_html("http://www.beeradvocate.com/lists/top/")
t <- top250web %>%
html_nodes("table") %>%
.[[1]]
##Parse Beer, Brewery, and Style, and add Rank
o <- t %>%
html_nodes("a") %>% ##gives beer, brewery, style
html_text()
BBS <- as.data.frame(matrix(o,nrow=250,ncol=3,byrow = TRUE))
BBS$Rank <- seq(1,250, by =1)
colnames(BBS) <- c("Beer", "Brewery", "Style", "Rank")
##Parse Rank, Beer, Hads remove bang from Hads, Merge with BBS
h <- t %>%
html_nodes("span") %>% ##gives rank, beer, hads
html_text()
h <- h[2:501]
RBH <- as.data.frame(matrix(h,nrow=250,ncol=2,byrow = TRUE))
colnames(RBH) <- c("Rank", "Ratings")
Merge1 <- merge(BBS, RBH, by.x = "Rank", by.y = "Rank")
Merge1[,5] <- gsub("\\W","",Merge1[,5])
##Parse Beer, Rating, Reviews, merge with Merge1
u <- t %>%
html_nodes("b") %>% ##gives beer, rating, reviews
html_text()
BRR <- as.data.frame(matrix(u,nrow=250,ncol=3,byrow = TRUE))
colnames(BRR) <- c("Beer", "Rating", "Reviews")
Merge2 <- merge(Merge1,BRR, by.x = "Beer", by.y = "Beer")
q <- t %>%
html_nodes("div") %>%
html_text()
abv <- as.data.frame(matrix(q,nrow=250,ncol=1,byrow = TRUE))
abv[,1] <- as.character(abv[,1])
pars <- function(x) word(x,-2,-2)
abv[,2] <- sapply(abv[,1],pars)
abv$Rank <- seq(1,250, by =1)
colnames(abv) <- c("Mush", "ABV", "Rank")
###Split apart ABV
# ABVSplit <- data.frame(String=character(),ABV=character())
#
# for (i in abv) {
#       if (str_count(i,"/") == 2){
#             String <- i ##word(i, 1, 2, " / ")
#             ABV <- word(i, 3, -1, " / ")
#       } else if ((str_count(i,"/") == 1)&(str_detect(i,'/ [:digit:]') == TRUE)){
#             String <- i ##word(i, 1, 1, " / ")
#             ABV <- word(i, 2, -1, " / ")
#       } else {
#             String <- i
#             ABV <- NA
#       }
#       df2 <- data.frame(String,ABV)
#       ABVSplit <- rbind(ABVSplit,df2)
# }
Merge3 <- merge(Merge2,abv, by = "Rank")
Top250 <- Merge3[c(1,2,3,4,9,6,5,7)]
rm(Merge1,o,Merge2,Merge3,h,t,u,BBS,BRR,RBH,abv,pars,q)
###Make Rank, Rating, Reviews and Hads numeric
for(i in c(1,7:ncol(Top250))) {Top250[,i] <- as.numeric(Top250[,i])}
Top250[,6] <- as.numeric(as.character(Top250[,6]))
###This will fix non-American letters back to the original
Top250[,2] <- as.character(Top250[,2])
Top250[,3] <- as.character(Top250[,3])
rownames(Top250) <- 1:250
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
Top250[,3] <- trim(Top250[,3])
Top250[,3] <- gsub("3", "Three",Top250[,3])
Top250[,3] <- gsub("Co\\.", "Company",Top250[,3])
Top250 <- Top250[order(Top250[,1]),]
Encoding(Top250[,2]) <- "UTF-8"
Encoding(Top250[,3]) <- "UTF-8"
Top250 <- Top250[,c(1,3,2,4:8)]
setwd("C:/Users/Stephen.P.Duffy/Documents/GitHub/BeerMaps/top250")
currentDate <- Sys.Date()
csvFileName <- paste("Top 250 Beers_",currentDate,".csv",sep="")
write.csv(Top250, file=csvFileName, row.names = FALSE)
setwd("C:/Users/Stephen.P.Duffy/Documents/GitHub/BeerMaps")
addr <- read.csv("brewery_addr.csv")
Top250 <- merge(Top250,addr,by = "Brewery")
Top250 <- Top250[order(Top250[,1]),]
##Save the data frame as a .csv
currentDate <- Sys.Date()
csvFileName <- paste("Top 250 Beers_Addr_",currentDate,".csv",sep="")
write.csv(Top250, file=csvFileName, row.names = FALSE)
rm(csvFileName,currentDate,addr,trim,top250web)
